# å¢å¼ºç‰ˆåŸºç¡€æ™ºèƒ½ä½“ç±»
# æä¾›é€šç”¨LLMè°ƒç”¨åŠŸèƒ½ï¼ŒåŒ…å«ç»Ÿè®¡ã€ç¼“å­˜ã€é‡è¯•ã€æ—¥å¿—ç­‰åŠŸèƒ½

import json
import uuid
import os
import sys
import time
import hashlib
from datetime import datetime
from typing import Dict, List, Any, Optional, Union
import requests
import random

# å¯é€‰ï¼šæ•°æ®åˆ†æåº“
try:
    import pandas as pd
    import numpy as np
    HAS_ANALYTICS = True
except ImportError:
    HAS_ANALYTICS = False

# å¯é€‰ï¼šä¸­æ–‡å¤„ç†åº“
try:
    import jieba
    HAS_JIEBA = True
except ImportError:
    HAS_JIEBA = False

from ..utils.config import API_CONFIG, SYSTEM_CONFIG, CURRENT_API


class EnhancedBaseAgent:
    """å¢å¼ºç‰ˆåŸºç¡€æ™ºèƒ½ä½“ç±»ï¼Œæä¾›é€šç”¨LLMè°ƒç”¨åŠŸèƒ½"""
    
    def __init__(self, name: str, config: Dict[str, Any] = None):
        self.name = name
        self.config = config or API_CONFIG
        self.model = self.config['model']
        self.temperature = self.config['temperature']
        self.max_tokens = self.config['max_tokens']
        self.api_key = self.config['api_key']
        self.base_url = self.config['base_url']
        
        # å¢å¼ºçš„ç»Ÿè®¡ä¿¡æ¯
        self.call_count = 0
        self.total_tokens = 0
        self.error_count = 0
        self.success_count = 0
        self.total_response_time = 0
        self.last_response_time = 0
        self.average_response_time = 0
        
        # ç¼“å­˜æœºåˆ¶
        self.response_cache = {}
        self.cache_enabled = True
        self.cache_hits = 0
        self.cache_misses = 0
        
        # é‡è¯•é…ç½®
        self.max_retries = SYSTEM_CONFIG.get('max_retries', 3)
        self.retry_delay = 1  # åˆå§‹é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
        
        # æ—¥å¿—è®°å½• - å¿…é¡»åœ¨_init_clientä¹‹å‰åˆå§‹åŒ–
        self.logs = []
        self.log_level = SYSTEM_CONFIG.get('log_level', 'INFO')
        
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        self._init_client()
        
        self._log(f"æ™ºèƒ½ä½“ {self.name} åˆå§‹åŒ–å®Œæˆ", "INFO")
    
    def _init_client(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        try:
            if CURRENT_API == "zhipuai":
                try:
                    from zhipuai import ZhipuAI
                    self.client = ZhipuAI(api_key=self.api_key)
                    self._log("æ™ºè°±AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ", "INFO")
                except ImportError:
                    self._log("zhipuaiåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install zhipuai", "ERROR")
                    self.client = None
            elif CURRENT_API == "openai":
                try:
                    import openai
                    openai.api_key = self.api_key
                    self.client = openai
                    self._log("OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ", "INFO")
                except ImportError:
                    self._log("openaiåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install openai", "ERROR")
                    self.client = None
            else:
                self.client = None
                self._log("è‡ªå®šä¹‰APIéœ€è¦æ‰‹åŠ¨å®ç°", "WARNING")
        except Exception as e:
            self._log(f"å¯¼å…¥APIå®¢æˆ·ç«¯å¤±è´¥: {e}", "ERROR")
            self.client = None
    
    def _log(self, message: str, level: str = "INFO"):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = {
            "timestamp": timestamp,
            "level": level,
            "agent": self.name,
            "message": message
        }
        self.logs.append(log_entry)
        
        # æ§åˆ¶å°è¾“å‡º
        if level == "ERROR":
            print(f"âŒ [{timestamp}] {self.name}: {message}")
        elif level == "WARNING":
            print(f"âš ï¸ [{timestamp}] {self.name}: {message}")
        elif level == "INFO":
            print(f"â„¹ï¸ [{timestamp}] {self.name}: {message}")
        else:
            print(f"ğŸ“ [{timestamp}] {self.name}: {message}")
    
    def _generate_cache_key(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        cache_data = {
            "messages": messages,
            "model": self.model,
            "temperature": kwargs.get('temperature', self.temperature),
            "max_tokens": kwargs.get('max_tokens', self.max_tokens)
        }
        cache_string = json.dumps(cache_data, sort_keys=True)
        return hashlib.md5(cache_string.encode()).hexdigest()
    
    def _get_from_cache(self, cache_key: str) -> Optional[str]:
        """ä»ç¼“å­˜è·å–å“åº”"""
        if not self.cache_enabled:
            return None
        
        if cache_key in self.response_cache:
            self.cache_hits += 1
            self._log(f"ç¼“å­˜å‘½ä¸­: {cache_key[:8]}...", "DEBUG")
            return self.response_cache[cache_key]
        
        self.cache_misses += 1
        return None
    
    def _save_to_cache(self, cache_key: str, response: str):
        """ä¿å­˜å“åº”åˆ°ç¼“å­˜"""
        if not self.cache_enabled:
            return
        
        # æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
        cache_limit = SYSTEM_CONFIG.get('cache_size_limit', 100)
        if len(self.response_cache) >= cache_limit:
            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
            oldest_key = next(iter(self.response_cache))
            del self.response_cache[oldest_key]
        
        self.response_cache[cache_key] = response
        self._log(f"å“åº”å·²ç¼“å­˜: {cache_key[:8]}...", "DEBUG")
    
    def call_llm(self, messages: List[Dict[str, str]], **kwargs) -> str:
        """è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        start_time = time.time()
        self.call_count += 1
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = self._generate_cache_key(messages, **kwargs)
        
        # å°è¯•ä»ç¼“å­˜è·å–
        cached_response = self._get_from_cache(cache_key)
        if cached_response:
            self.last_response_time = time.time() - start_time
            self.total_response_time += self.last_response_time
            self.average_response_time = self.total_response_time / self.call_count
            return cached_response
        
        # åˆå¹¶å‚æ•°
        params = {
            'temperature': kwargs.get('temperature', self.temperature),
            'max_tokens': kwargs.get('max_tokens', self.max_tokens)
        }
        
        # é‡è¯•æœºåˆ¶
        last_error = None
        for retry in range(self.max_retries):
            try:
                self._log(f"APIè°ƒç”¨å¼€å§‹ (å°è¯• {retry + 1}/{self.max_retries})", "DEBUG")
                
                if CURRENT_API == "zhipuai" and self.client:
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=messages,
                        **params
                    )
                    content = response.choices[0].message.content
                elif CURRENT_API == "openai" and self.client:
                    response = self.client.ChatCompletion.create(
                        model=self.model,
                        messages=messages,
                        **params
                    )
                    content = response.choices[0].message.content
                else:
                    # æ¨¡æ‹ŸAPIè°ƒç”¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰
                    content = self._mock_api_call(messages)
                
                # è®¡ç®—å“åº”æ—¶é—´
                self.last_response_time = time.time() - start_time
                self.total_response_time += self.last_response_time
                self.average_response_time = self.total_response_time / self.call_count
                
                # ç»Ÿè®¡tokenä½¿ç”¨é‡ï¼ˆä¼°ç®—ï¼‰
                estimated_tokens = len(str(messages)) + len(content)
                self.total_tokens += estimated_tokens
                
                # æˆåŠŸè®¡æ•°
                self.success_count += 1
                
                # ä¿å­˜åˆ°ç¼“å­˜
                self._save_to_cache(cache_key, content)
                
                self._log(f"APIè°ƒç”¨æˆåŠŸï¼Œå“åº”æ—¶é—´: {self.last_response_time:.2f}s", "INFO")
                return content
                
            except Exception as e:
                last_error = e
                self.error_count += 1
                self._log(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {retry + 1}/{self.max_retries}): {e}", "ERROR")
                
                if retry < self.max_retries - 1:
                    # æŒ‡æ•°é€€é¿
                    delay = self.retry_delay * (2 ** retry)
                    self._log(f"ç­‰å¾… {delay}s åé‡è¯•...", "INFO")
                    time.sleep(delay)
                else:
                    self._log(f"APIè°ƒç”¨æœ€ç»ˆå¤±è´¥: {e}", "ERROR")
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›å¤‡ç”¨å“åº”
        fallback_response = self._get_fallback_response(messages)
        self._save_to_cache(cache_key, fallback_response)
        return fallback_response
    
    def _mock_api_call(self, messages: List[Dict[str, str]]) -> str:
        """æ¨¡æ‹ŸAPIè°ƒç”¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        user_message = messages[-1]['content'] if messages else ""
        
        # æ ¹æ®æ¶ˆæ¯å†…å®¹è¿”å›æ¨¡æ‹Ÿå“åº”
        if "æ ‡ç­¾" in user_message:
            return json.dumps({
                "recommended_tags": {
                    "ç±»å‹æ ‡ç­¾": ["éƒ½å¸‚", "å¥‡å¹»"],
                    "ä¸»é¢˜æ ‡ç­¾": ["æˆé•¿", "å†’é™©"],
                    "é£æ ¼æ ‡ç­¾": ["è½»æ¾æ„‰å¿«"],
                    "å—ä¼—æ ‡ç­¾": ["å…¨å¹´é¾„"]
                },
                "reasoning": "åŸºäºç”¨æˆ·éœ€æ±‚æ¨è",
                "confidence": 0.8
            }, ensure_ascii=False)
        elif "äººç‰©" in user_message:
            return json.dumps({
                "basic_info": {
                    "name": "å¼ ä¸‰",
                    "age": 25,
                    "gender": "ç”·",
                    "occupation": "ç¨‹åºå‘˜"
                },
                "personality": {"description": "ä¹è§‚å¼€æœ—ï¼Œå–„äºæ€è€ƒ"},
                "appearance": {"description": "ä¸­ç­‰èº«æï¼Œæˆ´çœ¼é•œ"},
                "background": {
                    "core_desire": "è¿½æ±‚è‡ªç”±å’Œå†’é™©",
                    "fear": "å®³æ€•å¹³å‡¡",
                    "motivation": "æ”¹å˜ç°çŠ¶"
                },
                "skills": ["ç¼–ç¨‹", "é€»è¾‘æ€ç»´"]
            }, ensure_ascii=False)
        else:
            return "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„APIå“åº”ï¼Œè¯·é…ç½®çœŸå®çš„APIå¯†é’¥ã€‚"
    
    def _get_fallback_response(self, messages: List[Dict[str, str]]) -> str:
        """è·å–å¤‡ç”¨å“åº”"""
        self._log("ä½¿ç”¨å¤‡ç”¨å“åº”", "WARNING")
        return self._mock_api_call(messages)
    
    def parse_json_response(self, response: str) -> Dict[str, Any]:
        """è§£æJSONå“åº”å¹¶ç¡®ä¿åŒ…å«åŸºæœ¬ç»“æ„ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        if not response:
            self._log("æ”¶åˆ°ç©ºå“åº”", "WARNING")
            return {
                "title": "è§£æé”™è¯¯",
                "content": "ç©ºå“åº”",
                "error": "ç©ºå“åº”"
            }
        
        # å°è¯•å¤šç§JSONæå–æ–¹æ³•
        json_patterns = [
            r'```json\s*(\{.*?\})\s*```',  # markdownä»£ç å—
            r'```\s*(\{.*?\})\s*```',      # æ™®é€šä»£ç å—
            r'(\{.*\})',                   # ç›´æ¥JSON
        ]
        import re
        
        for pattern in json_patterns:
            matches = re.findall(pattern, response, re.DOTALL)
            if matches:
                try:
                    result = json.loads(matches[0])
                    self._log(f"JSONè§£ææˆåŠŸï¼Œä½¿ç”¨æ¨¡å¼: {pattern[:20]}...", "DEBUG")
                    return self._validate_json_structure(result)
                except json.JSONDecodeError as e:
                    self._log(f"JSONè§£æå¤±è´¥: {e}", "DEBUG")
                    continue
        
        # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œå°è¯•ç›´æ¥è§£æ
        try:
            result = json.loads(response)
            self._log("ç›´æ¥JSONè§£ææˆåŠŸ", "DEBUG")
            return self._validate_json_structure(result)
        except json.JSONDecodeError:
            pass
        
        # æœ€åå°è¯•æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
        start = response.find('{')
        end = response.rfind('}') + 1
        if start != -1 and end > start:
            try:
                result = json.loads(response[start:end])
                self._log("æå–JSONå¯¹è±¡æˆåŠŸ", "DEBUG")
                return self._validate_json_structure(result)
            except json.JSONDecodeError:
                pass
        
        # å¦‚æœä»ç„¶æ— æ³•è§£æï¼Œè¿”å›å¸¦æœ‰é»˜è®¤ç»“æ„çš„å­—å…¸
        self._log("JSONè§£æå®Œå…¨å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æ„", "WARNING")
        return {
            "title": "è§£æå¤±è´¥çš„ç« èŠ‚",
            "content": response[:500] + "..." if len(response) > 500 else response,
            "summary": "æ— æ³•ç”Ÿæˆç« èŠ‚æ¦‚è¦",
            "key_events": [],
            "foreshadowing": [],
            "error": "JSONè§£æå¤±è´¥"
        }
    
    def _validate_json_structure(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å’Œä¿®å¤JSONç»“æ„"""
        # ç¡®ä¿åŒ…å«åŸºæœ¬ç»“æ„
        if "content" in result:
            # ç¡®ä¿æœ‰æ ‡é¢˜
            if "title" not in result or not result["title"]:
                result["title"] = "æœªå‘½åç« èŠ‚"
        
        # æ·»åŠ æ—¶é—´æˆ³
        result["generated_at"] = datetime.now().isoformat()
        
        return result
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        success_rate = (self.success_count / max(self.call_count, 1)) * 100
        cache_hit_rate = (self.cache_hits / max(self.cache_hits + self.cache_misses, 1)) * 100
        
        return {
            "name": self.name,
            "call_count": self.call_count,
            "success_count": self.success_count,
            "error_count": self.error_count,
            "success_rate": round(success_rate, 2),
            "total_tokens": self.total_tokens,
            "total_response_time": round(self.total_response_time, 2),
            "average_response_time": round(self.average_response_time, 2),
            "last_response_time": round(self.last_response_time, 2),
            "cache_hits": self.cache_hits,
            "cache_misses": self.cache_misses,
            "cache_hit_rate": round(cache_hit_rate, 2),
            "cache_size": len(self.response_cache)
        }
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.call_count = 0
        self.total_tokens = 0
        self.error_count = 0
        self.success_count = 0
        self.total_response_time = 0
        self.last_response_time = 0
        self.average_response_time = 0
        self.cache_hits = 0
        self.cache_misses = 0
        self._log("ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®", "INFO")
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        cache_size = len(self.response_cache)
        self.response_cache.clear()
        self._log(f"å·²æ¸…ç©ºç¼“å­˜ï¼Œé‡Šæ”¾äº† {cache_size} ä¸ªç¼“å­˜é¡¹", "INFO")
    
    def get_logs(self, level: str = None) -> List[Dict[str, Any]]:
        """è·å–æ—¥å¿—è®°å½•"""
        if level:
            return [log for log in self.logs if log["level"] == level]
        return self.logs
    
    def export_logs(self, filename: str = None) -> str:
        """å¯¼å‡ºæ—¥å¿—åˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{self.name}_logs_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.logs, f, ensure_ascii=False, indent=2)
        
        self._log(f"æ—¥å¿—å·²å¯¼å‡ºåˆ°: {filename}", "INFO")
        return filename
