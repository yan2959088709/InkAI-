# å¢å¼ºç‰ˆè´¨é‡è¯„ä¼°æ™ºèƒ½ä½“
# åŒ…å«å¤šç»´åº¦è´¨é‡è¯„ä¼°ã€æ™ºèƒ½è¯„åˆ†ç³»ç»Ÿã€æ”¹è¿›å»ºè®®ç”Ÿæˆã€è´¨é‡è¶‹åŠ¿åˆ†æ

import json
from typing import Dict, List, Any, Optional
from datetime import datetime
import re

from ..core.base_agent import EnhancedBaseAgent


class EnhancedQualityAssessorAgent(EnhancedBaseAgent):
    """å¢å¼ºç‰ˆè´¨é‡è¯„ä¼°æ™ºèƒ½ä½“ - å¤šç»´åº¦æ™ºèƒ½è´¨é‡è¯„ä¼°ç³»ç»Ÿ"""
    
    def __init__(self):
        super().__init__("å¢å¼ºè´¨é‡è¯„ä¼°æ™ºèƒ½ä½“")
        
        # è´¨é‡è¯„ä¼°ç»´åº¦
        self.assessment_dimensions = {
            "å†…å®¹è´¨é‡": {
                "æƒé‡": 0.3,
                "å­ç»´åº¦": ["é€»è¾‘æ€§", "åˆ›æ–°æ€§", "æ·±åº¦", "å®Œæ•´æ€§"]
            },
            "æ–‡ç¬”è´¨é‡": {
                "æƒé‡": 0.25,
                "å­ç»´åº¦": ["è¯­è¨€æµç•…åº¦", "æ–‡é‡‡", "è¡¨è¾¾å‡†ç¡®æ€§", "é£æ ¼ä¸€è‡´æ€§"]
            },
            "ç»“æ„è´¨é‡": {
                "æƒé‡": 0.2,
                "å­ç»´åº¦": ["ç« èŠ‚ç»“æ„", "æƒ…èŠ‚å®‰æ’", "èŠ‚å¥æ§åˆ¶", "ä¼ç¬”è®¾ç½®"]
            },
            "äººç‰©è´¨é‡": {
                "æƒé‡": 0.15,
                "å­ç»´åº¦": ["äººç‰©ç«‹ä½“æ€§", "æ€§æ ¼ä¸€è‡´æ€§", "æˆé•¿å¼§çº¿", "å…³ç³»ç½‘ç»œ"]
            },
            "è¯»è€…ä½“éªŒ": {
                "æƒé‡": 0.1,
                "å­ç»´åº¦": ["å¯è¯»æ€§", "å¸å¼•åŠ›", "æƒ…æ„Ÿå…±é¸£", "è®°å¿†ç‚¹"]
            }
        }
        
        # è¯„åˆ†æ ‡å‡†
        self.scoring_criteria = {
            "ä¼˜ç§€": {"åˆ†æ•°èŒƒå›´": [90, 100], "æè¿°": "è¾¾åˆ°å‡ºç‰ˆæ ‡å‡†ï¼Œå…·æœ‰å•†ä¸šä»·å€¼"},
            "è‰¯å¥½": {"åˆ†æ•°èŒƒå›´": [80, 89], "æè¿°": "è´¨é‡è¾ƒé«˜ï¼Œæœ‰æ”¹è¿›ç©ºé—´"},
            "ä¸€èˆ¬": {"åˆ†æ•°èŒƒå›´": [70, 79], "æè¿°": "åŸºæœ¬åˆæ ¼ï¼Œéœ€è¦æ”¹è¿›"},
            "è¾ƒå·®": {"åˆ†æ•°èŒƒå›´": [60, 69], "æè¿°": "å­˜åœ¨æ˜æ˜¾é—®é¢˜ï¼Œéœ€è¦å¤§å¹…æ”¹è¿›"},
            "ä¸åˆæ ¼": {"åˆ†æ•°èŒƒå›´": [0, 59], "æè¿°": "è´¨é‡ä¸è¾¾æ ‡ï¼Œéœ€è¦é‡æ–°åˆ›ä½œ"}
        }
        
        self._log("å¢å¼ºç‰ˆè´¨é‡è¯„ä¼°æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ", "INFO")
    
    def assess_content_quality(self, content: str, content_type: str = "ç« èŠ‚") -> Dict[str, Any]:
        """è¯„ä¼°å†…å®¹è´¨é‡"""
        self._log(f"å¼€å§‹è¯„ä¼°{content_type}è´¨é‡", "INFO")
        
        # åŸºç¡€è´¨é‡æ£€æŸ¥
        basic_quality = self._basic_quality_check(content)
        
        # æ·±åº¦è´¨é‡åˆ†æ
        deep_analysis = self._deep_quality_analysis(content, content_type)
        
        # ç»¼åˆè¯„åˆ†
        overall_score = self._calculate_overall_score(basic_quality, deep_analysis)
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        improvement_suggestions = self._generate_improvement_suggestions(basic_quality, deep_analysis)
        
        result = {
            "content_type": content_type,
            "overall_score": overall_score,
            "quality_level": self._get_quality_level(overall_score),
            "dimension_scores": {
                "å†…å®¹è´¨é‡": basic_quality.get("content_score", 0),
                "æ–‡ç¬”è´¨é‡": basic_quality.get("writing_score", 0),
                "ç»“æ„è´¨é‡": basic_quality.get("structure_score", 0),
                "äººç‰©è´¨é‡": deep_analysis.get("character_score", 0),
                "è¯»è€…ä½“éªŒ": deep_analysis.get("experience_score", 0)
            },
            "detailed_analysis": {
                "basic_quality": basic_quality,
                "deep_analysis": deep_analysis
            },
            "improvement_suggestions": improvement_suggestions,
            "assessment_time": datetime.now().isoformat()
        }
        
        self._log(f"{content_type}è´¨é‡è¯„ä¼°å®Œæˆï¼Œæ€»åˆ†: {overall_score}", "INFO")
        return result
    
    def _basic_quality_check(self, content: str) -> Dict[str, Any]:
        """åŸºç¡€è´¨é‡æ£€æŸ¥"""
        analysis = {
            "content_score": 0,
            "writing_score": 0,
            "structure_score": 0,
            "issues": [],
            "strengths": []
        }
        
        # å†…å®¹è´¨é‡æ£€æŸ¥
        if len(content) > 100:
            analysis["content_score"] += 20
            analysis["strengths"].append("å†…å®¹é•¿åº¦é€‚ä¸­")
        else:
            analysis["issues"].append("å†…å®¹è¿‡çŸ­")
        
        # æ–‡ç¬”è´¨é‡æ£€æŸ¥
        if self._check_language_fluency(content):
            analysis["writing_score"] += 25
            analysis["strengths"].append("è¯­è¨€æµç•…")
        else:
            analysis["issues"].append("è¯­è¨€ä¸å¤Ÿæµç•…")
        
        # ç»“æ„è´¨é‡æ£€æŸ¥
        if self._check_structure_quality(content):
            analysis["structure_score"] += 25
            analysis["strengths"].append("ç»“æ„æ¸…æ™°")
        else:
            analysis["issues"].append("ç»“æ„éœ€è¦ä¼˜åŒ–")
        
        return analysis
    
    def _deep_quality_analysis(self, content: str, content_type: str) -> Dict[str, Any]:
        """æ·±åº¦è´¨é‡åˆ†æ"""
        prompt = f"""
        è¯·å¯¹ä»¥ä¸‹{content_type}å†…å®¹è¿›è¡Œæ·±åº¦è´¨é‡åˆ†æï¼š
        å†…å®¹ï¼š{content[:1000]}...
        
        è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œè¯„ä¼°ï¼š
        1. å†…å®¹è´¨é‡ï¼šé€»è¾‘æ€§ã€åˆ›æ–°æ€§ã€æ·±åº¦ã€å®Œæ•´æ€§
        2. æ–‡ç¬”è´¨é‡ï¼šè¯­è¨€æµç•…åº¦ã€æ–‡é‡‡ã€è¡¨è¾¾å‡†ç¡®æ€§ã€é£æ ¼ä¸€è‡´æ€§
        3. ç»“æ„è´¨é‡ï¼šç« èŠ‚ç»“æ„ã€æƒ…èŠ‚å®‰æ’ã€èŠ‚å¥æ§åˆ¶ã€ä¼ç¬”è®¾ç½®
        4. äººç‰©è´¨é‡ï¼šäººç‰©ç«‹ä½“æ€§ã€æ€§æ ¼ä¸€è‡´æ€§ã€æˆé•¿å¼§çº¿ã€å…³ç³»ç½‘ç»œ
        5. è¯»è€…ä½“éªŒï¼šå¯è¯»æ€§ã€å¸å¼•åŠ›ã€æƒ…æ„Ÿå…±é¸£ã€è®°å¿†ç‚¹
        
        è¯·è¿”å›JSONæ ¼å¼ï¼š
        {{
            "content_quality": {{
                "logic_score": åˆ†æ•°(0-100),
                "innovation_score": åˆ†æ•°(0-100),
                "depth_score": åˆ†æ•°(0-100),
                "completeness_score": åˆ†æ•°(0-100),
                "analysis": "è¯¦ç»†åˆ†æ"
            }},
            "writing_quality": {{
                "fluency_score": åˆ†æ•°(0-100),
                "literary_score": åˆ†æ•°(0-100),
                "accuracy_score": åˆ†æ•°(0-100),
                "consistency_score": åˆ†æ•°(0-100),
                "analysis": "è¯¦ç»†åˆ†æ"
            }},
            "structure_quality": {{
                "chapter_structure_score": åˆ†æ•°(0-100),
                "plot_arrangement_score": åˆ†æ•°(0-100),
                "rhythm_control_score": åˆ†æ•°(0-100),
                "foreshadowing_score": åˆ†æ•°(0-100),
                "analysis": "è¯¦ç»†åˆ†æ"
            }},
            "character_quality": {{
                "dimensionality_score": åˆ†æ•°(0-100),
                "consistency_score": åˆ†æ•°(0-100),
                "growth_arc_score": åˆ†æ•°(0-100),
                "relationship_score": åˆ†æ•°(0-100),
                "analysis": "è¯¦ç»†åˆ†æ"
            }},
            "reader_experience": {{
                "readability_score": åˆ†æ•°(0-100),
                "attractiveness_score": åˆ†æ•°(0-100),
                "emotional_resonance_score": åˆ†æ•°(0-100),
                "memorability_score": åˆ†æ•°(0-100),
                "analysis": "è¯¦ç»†åˆ†æ"
            }},
            "overall_analysis": "ç»¼åˆåˆ†æå’Œå»ºè®®"
        }}
        """
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´è´¨é‡è¯„ä¼°ä¸“å®¶ï¼Œå…·æœ‰ä¸°å¯Œçš„æ–‡å­¦æ‰¹è¯„ç»éªŒå’Œå‡ºç‰ˆè¡Œä¸šèƒŒæ™¯ã€‚ä½ èƒ½å¤Ÿä»å¤šä¸ªç»´åº¦å®¢è§‚è¯„ä¼°å°è¯´è´¨é‡ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        response = self.call_llm(messages)
        result = self.parse_json_response(response)
        
        # è®¡ç®—å„ç»´åº¦å¾—åˆ†
        dimension_scores = {}
        for dimension, data in result.items():
            if isinstance(data, dict) and "score" in str(data):
                scores = [v for k, v in data.items() if k.endswith("_score") and isinstance(v, (int, float))]
                if scores:
                    dimension_scores[dimension] = sum(scores) / len(scores)
        
        result["dimension_scores"] = dimension_scores
        return result
    
    def _calculate_overall_score(self, basic_quality: Dict[str, Any], deep_analysis: Dict[str, Any]) -> float:
        """è®¡ç®—ç»¼åˆå¾—åˆ†"""
        # åŸºç¡€è´¨é‡å¾—åˆ†
        basic_score = (
            basic_quality.get("content_score", 0) * 0.3 +
            basic_quality.get("writing_score", 0) * 0.35 +
            basic_quality.get("structure_score", 0) * 0.35
        )
        
        # æ·±åº¦åˆ†æå¾—åˆ†
        deep_scores = deep_analysis.get("dimension_scores", {})
        deep_score = sum(deep_scores.values()) / max(len(deep_scores), 1)
        
        # ç»¼åˆå¾—åˆ†ï¼ˆåŸºç¡€è´¨é‡40%ï¼Œæ·±åº¦åˆ†æ60%ï¼‰
        overall_score = basic_score * 0.4 + deep_score * 0.6
        return round(overall_score, 2)
    
    def _generate_improvement_suggestions(self, basic_quality: Dict[str, Any], deep_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []
        
        # åŸºäºåŸºç¡€è´¨é‡é—®é¢˜çš„å»ºè®®
        for issue in basic_quality.get("issues", []):
            if "å†…å®¹è¿‡çŸ­" in issue:
                suggestions.append({
                    "type": "å†…å®¹æ‰©å±•",
                    "priority": "é«˜",
                    "suggestion": "å¢åŠ æ›´å¤šç»†èŠ‚æè¿°å’Œæƒ…èŠ‚å‘å±•",
                    "implementation": "å¯ä»¥æ·»åŠ ç¯å¢ƒæå†™ã€äººç‰©å¿ƒç†æ´»åŠ¨ã€å¯¹è¯ç»†èŠ‚ç­‰"
                })
            elif "è¯­è¨€ä¸å¤Ÿæµç•…" in issue:
                suggestions.append({
                    "type": "æ–‡ç¬”æ”¹è¿›",
                    "priority": "é«˜",
                    "suggestion": "ä¼˜åŒ–è¯­è¨€è¡¨è¾¾ï¼Œæé«˜æµç•…åº¦",
                    "implementation": "æ£€æŸ¥å¥å¼ç»“æ„ï¼Œé¿å…é‡å¤ç”¨è¯ï¼Œå¢åŠ è¯­è¨€å˜åŒ–"
                })
            elif "ç»“æ„éœ€è¦ä¼˜åŒ–" in issue:
                suggestions.append({
                    "type": "ç»“æ„ä¼˜åŒ–",
                    "priority": "ä¸­",
                    "suggestion": "é‡æ–°ç»„ç»‡å†…å®¹ç»“æ„",
                    "implementation": "ç¡®ä¿é€»è¾‘æ¸…æ™°ï¼Œæ®µè½å®‰æ’åˆç†ï¼Œè¿‡æ¸¡è‡ªç„¶"
                })
        
        # åŸºäºæ·±åº¦åˆ†æçš„å»ºè®®
        dimension_scores = deep_analysis.get("dimension_scores", {})
        for dimension, score in dimension_scores.items():
            if score < 70:
                suggestions.append({
                    "type": f"{dimension}æå‡",
                    "priority": "ä¸­",
                    "suggestion": f"æå‡{dimension}æ°´å¹³",
                    "implementation": f"é’ˆå¯¹{dimension}çš„å…·ä½“é—®é¢˜è¿›è¡Œæ”¹è¿›"
                })
        
        return suggestions
    
    def _check_language_fluency(self, content: str) -> bool:
        """æ£€æŸ¥è¯­è¨€æµç•…åº¦"""
        # ç®€å•çš„æµç•…åº¦æ£€æŸ¥
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
        if len(sentences) < 3:
            return False
        
        # æ£€æŸ¥å¥å­é•¿åº¦å˜åŒ–
        sentence_lengths = [len(s) for s in sentences if s.strip()]
        if len(sentence_lengths) < 2:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„è¯è¯­
        words = content.split()
        if len(words) < 10:
            return False
        
        return True
    
    def _check_structure_quality(self, content: str) -> bool:
        """æ£€æŸ¥ç»“æ„è´¨é‡"""
        # ç®€å•çš„ç»“æ„æ£€æŸ¥
        if len(content) < 200:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ®µè½åˆ†éš”
        if '\n' not in content and 'ã€‚' not in content:
            return False
        
        return True
    
    def _get_quality_level(self, score: float) -> str:
        """è·å–è´¨é‡ç­‰çº§"""
        for level, criteria in self.scoring_criteria.items():
            min_score, max_score = criteria["åˆ†æ•°èŒƒå›´"]
            if min_score <= score <= max_score:
                return level
        return "ä¸åˆæ ¼"
    
    def assess_novel_overall_quality(self, novel_data: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°æ•´éƒ¨å°è¯´çš„ç»¼åˆè´¨é‡"""
        self._log("å¼€å§‹è¯„ä¼°æ•´éƒ¨å°è¯´è´¨é‡", "INFO")
        
        assessment_results = {
            "novel_id": novel_data.get("id", "unknown"),
            "assessment_time": datetime.now().isoformat(),
            "overall_quality": {},
            "chapter_quality": [],
            "character_quality": {},
            "storyline_quality": {},
            "improvement_plan": []
        }
        
        # è¯„ä¼°å„ç« èŠ‚è´¨é‡
        chapters = novel_data.get("chapters", [])
        chapter_scores = []
        for chapter in chapters:
            chapter_content = chapter.get("content", "")
            if chapter_content:
                chapter_assessment = self.assess_content_quality(chapter_content, "ç« èŠ‚")
                assessment_results["chapter_quality"].append({
                    "chapter_id": chapter.get("id", "unknown"),
                    "chapter_title": chapter.get("title", "æœªå‘½å"),
                    "quality_score": chapter_assessment["overall_score"],
                    "quality_level": chapter_assessment["quality_level"]
                })
                chapter_scores.append(chapter_assessment["overall_score"])
        
        # è®¡ç®—ç« èŠ‚è´¨é‡ç»Ÿè®¡
        if chapter_scores:
            assessment_results["chapter_quality_stats"] = {
                "average_score": sum(chapter_scores) / len(chapter_scores),
                "highest_score": max(chapter_scores),
                "lowest_score": min(chapter_scores),
                "quality_consistency": max(chapter_scores) - min(chapter_scores)
            }
        
        # è¯„ä¼°äººç‰©è´¨é‡
        characters = novel_data.get("characters", [])
        if characters:
            character_assessment = self._assess_character_quality(characters)
            assessment_results["character_quality"] = character_assessment
        
        # è¯„ä¼°æ•…äº‹çº¿è´¨é‡
        storyline = novel_data.get("storyline", {})
        if storyline:
            storyline_assessment = self._assess_storyline_quality(storyline)
            assessment_results["storyline_quality"] = storyline_assessment
        
        # ç”Ÿæˆæ•´ä½“æ”¹è¿›è®¡åˆ’
        improvement_plan = self._generate_novel_improvement_plan(assessment_results)
        assessment_results["improvement_plan"] = improvement_plan
        
        self._log("æ•´éƒ¨å°è¯´è´¨é‡è¯„ä¼°å®Œæˆ", "INFO")
        return assessment_results
    
    def _assess_character_quality(self, characters: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è¯„ä¼°äººç‰©è´¨é‡"""
        assessment = {
            "character_count": len(characters),
            "main_character_quality": 0,
            "supporting_character_quality": 0,
            "character_consistency": 0,
            "issues": [],
            "strengths": []
        }
        
        main_characters = [c for c in characters if c.get("character_type") == "ä¸»è§’"]
        supporting_characters = [c for c in characters if c.get("character_type") == "é…è§’"]
        
        if main_characters:
            assessment["main_character_quality"] = 85  # ç®€åŒ–è¯„åˆ†
            assessment["strengths"].append("ä¸»è§’è®¾å®šå®Œæ•´")
        else:
            assessment["issues"].append("ç¼ºå°‘ä¸»è§’è®¾å®š")
        
        if supporting_characters:
            assessment["supporting_character_quality"] = 75  # ç®€åŒ–è¯„åˆ†
            assessment["strengths"].append("é…è§’è®¾å®šä¸°å¯Œ")
        else:
            assessment["issues"].append("é…è§’è®¾å®šä¸è¶³")
        
        return assessment
    
    def _assess_storyline_quality(self, storyline: Dict[str, Any]) -> Dict[str, Any]:
        """è¯„ä¼°æ•…äº‹çº¿è´¨é‡"""
        assessment = {
            "structure_completeness": 0,
            "plot_development": 0,
            "conflict_design": 0,
            "world_building": 0,
            "issues": [],
            "strengths": []
        }
        
        # æ£€æŸ¥æ•…äº‹ç»“æ„å®Œæ•´æ€§
        if "three_act_structure" in storyline:
            three_act = storyline["three_act_structure"]
            if all(act in three_act for act in ["act1", "act2", "act3"]):
                assessment["structure_completeness"] = 90
                assessment["strengths"].append("æ•…äº‹ç»“æ„å®Œæ•´")
            else:
                assessment["issues"].append("æ•…äº‹ç»“æ„ä¸å®Œæ•´")
        
        # æ£€æŸ¥æ ¸å¿ƒå†²çª
        if "main_conflict" in storyline:
            assessment["conflict_design"] = 80
            assessment["strengths"].append("æ ¸å¿ƒå†²çªæ˜ç¡®")
        else:
            assessment["issues"].append("æ ¸å¿ƒå†²çªä¸æ˜ç¡®")
        
        return assessment
    
    def _generate_novel_improvement_plan(self, assessment_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ•´éƒ¨å°è¯´çš„æ”¹è¿›è®¡åˆ’"""
        plan = []
        
        # åŸºäºç« èŠ‚è´¨é‡çš„æ”¹è¿›å»ºè®®
        chapter_stats = assessment_results.get("chapter_quality_stats", {})
        if chapter_stats:
            avg_score = chapter_stats.get("average_score", 0)
            if avg_score < 70:
                plan.append({
                    "priority": "é«˜",
                    "area": "ç« èŠ‚è´¨é‡",
                    "action": "æå‡ç« èŠ‚æ•´ä½“è´¨é‡",
                    "target": f"å°†å¹³å‡åˆ†ä»{avg_score}æå‡åˆ°80ä»¥ä¸Š"
                })
        
        # åŸºäºäººç‰©è´¨é‡çš„æ”¹è¿›å»ºè®®
        character_quality = assessment_results.get("character_quality", {})
        if character_quality.get("issues"):
            plan.append({
                "priority": "ä¸­",
                "area": "äººç‰©è®¾å®š",
                "action": "å®Œå–„äººç‰©è®¾å®š",
                "target": "è§£å†³äººç‰©è®¾å®šä¸­çš„é—®é¢˜"
            })
        
        return plan
    
    def generate_quality_report(self, assessment_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆè´¨é‡è¯„ä¼°æŠ¥å‘Š"""
        report = f"""
# å°è¯´è´¨é‡è¯„ä¼°æŠ¥å‘Š

## ğŸ“Š æ€»ä½“è¯„ä¼°
- **è¯„ä¼°æ—¶é—´**: {assessment_results.get('assessment_time', 'æœªçŸ¥')}
- **å°è¯´ID**: {assessment_results.get('novel_id', 'æœªçŸ¥')}

## ğŸ“– ç« èŠ‚è´¨é‡åˆ†æ
"""
        
        chapter_stats = assessment_results.get("chapter_quality_stats", {})
        if chapter_stats:
            report += f"""
- **å¹³å‡è´¨é‡å¾—åˆ†**: {chapter_stats.get('average_score', 0):.1f}
- **æœ€é«˜å¾—åˆ†**: {chapter_stats.get('highest_score', 0):.1f}
- **æœ€ä½å¾—åˆ†**: {chapter_stats.get('lowest_score', 0):.1f}
- **è´¨é‡ä¸€è‡´æ€§**: {chapter_stats.get('quality_consistency', 0):.1f}
"""
        
        # æ·»åŠ æ”¹è¿›è®¡åˆ’
        improvement_plan = assessment_results.get("improvement_plan", [])
        if improvement_plan:
            report += "\n## ğŸ¯ æ”¹è¿›è®¡åˆ’\n"
            for i, item in enumerate(improvement_plan, 1):
                report += f"""
{i}. **{item['area']}** (ä¼˜å…ˆçº§: {item['priority']})
   - è¡ŒåŠ¨: {item['action']}
   - ç›®æ ‡: {item['target']}
"""
        
        return report
